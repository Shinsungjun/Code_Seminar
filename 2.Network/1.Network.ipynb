{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Architecture를 짜는 방법에 대해 알아봅시다  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Format  \n",
    "네트워크는 기본적으로 torch.nn의 nn.Module을 상속받아 사용합니다  \n",
    "또한 상속한 nn.Module의 attribute (self.training)등을 사용하기 위해 super 를 이용해서 상속받습니다  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() #super().__init__() -> nn.Module의 init을 한다고 생각하면 됨! init하면서 상속을 받음\n",
    "                           #super(지금Classname, self).__init__() -> python2 문법\n",
    "                           #super().__init__() -> python3 문법 python 3가 더 간단하니 3로 쓰는걸로 ..\n",
    "        self.conv = nn.Conv2d(3, 6, kernel_size=3, stride=2, padding=1) #3, 2, 1 -> 1/2 resolution\n",
    "        self.conv2 = nn.Conv2d(6, 12, 3, 2, 1)\n",
    "        self.conv3 = nn.Conv2d(12, 24, 3, 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward method가 __call__ method 처럼 작동하게 됨!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape (1/8 resolution) : torch.Size([1, 24, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "backbone = Backbone()\n",
    "x = torch.ones((1, 3, 100, 100)) #B, C, H, W\n",
    "x = backbone(x) #backbone.forward(x)가 아닌 __call__ method 처럼 backbone(x) 이렇게 사용\n",
    "print(f\"x shape (1/8 resolution) : {x.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "super().__init__()을 쓰면서 self.training이라는 attribute를 우리는 선언하지 않았지만, 상속받아 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "backbone.train()\n",
    "print(backbone.training)\n",
    "\n",
    "backbone.eval()\n",
    "print(backbone.training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 train과 eval 모드에 따라 inference시 forward에서 return이 달라질 수 있는데 이를 self.training으로 컨트롤 하는 방식을 많이 사용함  \n",
    "nn.Module에 지원하는 method가 많으니 찾아보시길! (apply 함수 등등 .. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() #super().__init__() -> nn.Module의 init을 한다고 생각하면 됨! init하면서 상속을 받음\n",
    "                           #super(지금Classname, self).__init__() -> python2 문법\n",
    "                           #super().__init__() -> python3 문법 python 3가 더 간단하니 3로 쓰는걸로 ..\n",
    "        self.conv = nn.Conv2d(3, 6, kernel_size=3, stride=2, padding=1) #3, 2, 1 -> 1/2 resolution\n",
    "        self.conv2 = nn.Conv2d(6, 12, 3, 2, 1)\n",
    "        self.conv3 = nn.Conv2d(12, 24, 3, 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        if self.training:\n",
    "            ...\n",
    "        else:\n",
    "            ...\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 요즘 trend는 Network 내부에 Loss를 두는 경우가 많아 training시에는 loss 계산 후, loss 값만 Return하고  \n",
    "training이 아니고 eval을 하는 경우는 결과물까지 visualization 해야하는 경우가 많기 때문에 loss 값과 output 모두 내도록 Return!  \n",
    "꼭 이렇게 쓰이는건 아니고 .. 그리고 training시에, eval시에 다른 operation을 해야하는 경우가 많은데 그럴 때 사용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 필요한 attribute 선언 ..\n",
    "        # Loss 구현의 자세한 점은 추후 Loss Part에서 ..\n",
    "        self.criterion = nn.L1Loss()\n",
    "    def forward(self, x, target):\n",
    "        loss = self.criterion(x, target)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3, 6, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 3, 2, 1)\n",
    "        self.conv3 = nn.Conv2d(12, 24, 3, 2, 1)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(24, 1, 3, 1, 1)\n",
    "        self.loss = Loss()\n",
    "    def forward(self, x, target):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        loss = self.loss(x, target)\n",
    "        if self.training:\n",
    "            return loss\n",
    "        else:\n",
    "            return loss, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 1.146078109741211\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((1, 3, 100, 100))\n",
    "target = torch.ones((1, 1, 13, 13))\n",
    "\n",
    "network = Network()\n",
    "network.train()\n",
    "\n",
    "loss = network(x, target)\n",
    "print(f\"loss : {loss}\")\n",
    "#loss 계산 후 backward 함수를 통해 upate 필요 ~\n",
    "\n",
    "network.eval()\n",
    "loss, output = network(x, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a82ec9c67520d8d8366367003340c67b1755b8f934fa1115298f141d8d2f8979"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('pyml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
