{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code를 보면서 많이 볼 수 있는 어색한 문법?들에 대해 모아둡니다!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch나 Numpy에서 [None] [None,None] 이런 문법을 굉장히 많이 볼 수 있습니다  \n",
    "처음에 보면 인덱스을 넣을 자리에 None을 넣는게 도대체 뭐하는건지 혼란스럽습니다  \n",
    "None을 넣는건 Torch에서 unsqueeze() 함수처럼 차원을 하나 늘려준다고 생각하면 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Tensor---\n",
      "f1 shape : torch.Size([3, 8, 8])\n",
      "f2 shape : torch.Size([1, 3, 8, 8])\n",
      "f3 shape : torch.Size([1, 1, 3, 8, 8]), f4 shape : torch.Size([3, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "print(\"---Tensor---\")\n",
    "f1 = torch.ones((3, 8, 8))\n",
    "f2 = f1[None]\n",
    "f3 = f1[None, None]\n",
    "f4 = f1[:,None]\n",
    "print(f\"f1 shape : {f1.shape}\\nf2 shape : {f2.shape}\\nf3 shape : {f3.shape},\\nf4 shape : {f4.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Numpy---\n",
      "f1 shape : (3, 8, 8)\n",
      "f2 shape : (1, 3, 8, 8)\n",
      "f3 shape : (3, 8, 8, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"---Numpy---\")\n",
    "f1 = np.ones((3, 8, 8))\n",
    "f2 = f1[None]\n",
    "f3 = f1[:, :, :, None, None]\n",
    "print(f\"f1 shape : {f1.shape}\\nf2 shape : {f2.shape}\\nf3 shape : {f3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위과 같이 차원을 늘리는 경우가 많습니다!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인덱스에 ... 을 쓰는 경우  \n",
    "code 중에 [ ] 안에 ... 가 들어가 있는 경우가 많습니다.  \n",
    "간단히 말하면 [:] 에서 : 를 여러번 쓰기 귀찮을 경우 ... 를 적는 경우입니다.  \n",
    "4차원 tensor에서 B x C x H x W 에서 W만 건드리고 싶은경우  \n",
    "tensor[:, :, :, 5] == tensor[..., 5] 입니다.  \n",
    "tensor[:, ... , 5] 어디든지 들어가서 : 여러개 쓰는 것 대신 쓸 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0., 0.]]]])\n",
      "tensor([[[1., 1., 1., 1., 1.]]]) tensor([[[1., 1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "f1 = torch.zeros((1, 1, 5, 5))\n",
    "print(f1)\n",
    "f1[:, :, :, 2] = 1\n",
    "print(f1)\n",
    "f2 = f1[:, :, :, 2] #차원이 명확함\n",
    "f3 = f1[..., 2] #직관적이진 않음 .. 근데 많이들 씀 ..\n",
    "\n",
    "print(f2, f3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a82ec9c67520d8d8366367003340c67b1755b8f934fa1115298f141d8d2f8979"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('pyml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
